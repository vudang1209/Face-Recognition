import os
import cv2
import numpy as np
from architecture import InceptionResNetV2
from sklearn.preprocessing import Normalizer
from database import connect_db, create_table, insert_encoding
from custom_mtcnn import CustomMTCNN
from tkinter import Tk
from tkinter.filedialog import askopenfilenames
import matplotlib.pyplot as plt

required_shape = (160, 160)
face_encoder = InceptionResNetV2()
face_encoder.load_weights("./src/facenet_keras_weights.h5")
detector = CustomMTCNN()
l2_normalizer = Normalizer('l2')

def normalize(img):
    mean, std = img.mean(), img.std()
    return (img - mean) / std

def display_intermediate_results(img_rgb, stages_data, image_path):
    plt.figure(figsize=(15, 5))

    # G·ªëc
    plt.subplot(1, 4, 1)
    plt.imshow(img_rgb)
    plt.title("·∫¢nh g·ªëc")
    plt.axis('off')

    stages = ['P-Net', 'R-Net', 'O-Net']
    for i, stage_name in enumerate(stages):
        stage_data = stages_data.get(stage_name)
        if stage_data is not None:
            plt.subplot(1, 4, i + 2)
            plt.imshow(cv2.cvtColor(stage_data, cv2.COLOR_BGR2RGB))
            plt.title(stage_name)
            plt.axis('off')

    plt.suptitle(f"K·∫øt qu·∫£ MTCNN: {os.path.basename(image_path)}")
    plt.tight_layout()
    plt.show()

def collect_faces_from_images(image_paths, ma_sv, ho_ten):
    label = f"{ma_sv}_{ho_ten.replace(' ', '_')}"
    conn = connect_db()
    create_table(conn)

    for image_path in image_paths:
        print(f"üîç ƒêang x·ª≠ l√Ω ·∫£nh: {image_path}")
        img = cv2.imread(image_path)
        if img is None:
            print(f"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {image_path}")
            continue

        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        try:
            # L·∫•y k·∫øt qu·∫£ v√† ·∫£nh trung gian t·ª´ c√°c giai ƒëo·∫°n c·ªßa MTCNN
            results, pnet_img, rnet_img, onet_img = detector.detect_and_visualize(img_rgb)
        except Exception as e:
            print(f"L·ªói khi x·ª≠ l√Ω MTCNN: {e}")
            continue

        if results is None or len(results) == 0:
            print(f"Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t trong ·∫£nh: {image_path}")
            continue

        # Hi·ªÉn th·ªã pipeline trung gian
        stages_data = {
            "P-Net": pnet_img,
            "R-Net": rnet_img,
            "O-Net": onet_img
        }
        display_intermediate_results(img_rgb, stages_data, image_path)

        for i, res in enumerate(results):
            if isinstance(res, dict) and 'box' in res:
                x, y, w, h = res['box']
            elif isinstance(res, (list, tuple, np.ndarray)) and len(res) == 4:
                x, y, w, h = res
            else:
                print(f"Kh√¥ng th·ªÉ ph√¢n t√≠ch res: {res}")
                continue

            x, y = abs(int(x)), abs(int(y))
            face = img_rgb[y:y + int(h), x:x + int(w)]

            face = normalize(face)
            face = cv2.resize(face, required_shape)
            encode = face_encoder.predict(np.expand_dims(face, axis=0))[0]
            encode = l2_normalizer.transform(np.expand_dims(encode, axis=0))[0]

            insert_encoding(conn, label, encode.tobytes())
            print(f"ƒê√£ l∆∞u khu√¥n m·∫∑t {i+1} t·ª´ ·∫£nh: {image_path}")

    conn.close()
    print("Ho√†n t·∫•t thu th·∫≠p khu√¥n m·∫∑t t·ª´ c√°c ·∫£nh.")

if __name__ == "__main__":
    Tk().withdraw()
    image_paths = askopenfilenames(title="Ch·ªçn ·∫£nh", filetypes=[("Image Files", "*.jpg;*.jpeg;*.png")])

    if not image_paths:
        print("Kh√¥ng c√≥ ·∫£nh n√†o ƒë∆∞·ª£c ch·ªçn.")
    else:
        ma_sv = input("Nh·∫≠p m√£ sinh vi√™n: ")
        ho_ten = input("Nh·∫≠p h·ªç t√™n: ")
        collect_faces_from_images(image_paths, ma_sv, ho_ten)
